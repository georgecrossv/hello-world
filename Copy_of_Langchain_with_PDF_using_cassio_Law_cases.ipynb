{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgecrossv/hello-world/blob/master/Copy_of_Langchain_with_PDF_using_cassio_Law_cases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLHkt-bMq4up"
      },
      "source": [
        "# Langchain Retrieval Augmentation (using Law data)\n",
        "Large Language Models (LLMs) have a data freshness problem. The most powerful LLMs in the world, like GPT-4, have no idea about recent world events.\n",
        "\n",
        "The world of LLMs is frozen in time. Their world exists as a static snapshot of the world as it was within their training data.\n",
        "\n",
        "A solution to this problem is retrieval augmentation. The idea behind this is that we retrieve relevant information from an external knowledge base and give that information to our LLM. In this notebook we will learn how to do that. In this demo, external or proprietary data will be stored in Astra DB and used to provide more current LLM responses."
      ],
      "id": "oLHkt-bMq4up"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUeV_S5q4u0"
      },
      "source": [
        "## Colab-specific setup"
      ],
      "id": "WQUeV_S5q4u0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1p8iUgjq4u2"
      },
      "source": [
        "Make sure you have a Database and get ready to upload the Secure Connect Bundle and supply the Token string\n",
        "(see [Pre-requisites](https://cassio.org/start_here/#vector-database) on cassio.org for details).\n",
        "\n",
        "Likewise, ensure you have the necessary secret for the LLM provider of your choice: you'll be asked to input it shortly\n",
        "(see [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for details).\n",
        "\n",
        "_Note: some portions of this notebook is part of the CassIO documentation. Visit [this page on cassIO.org](https://cassio.org/frameworks/langchain/qa-basic/)._\n"
      ],
      "id": "Z1p8iUgjq4u2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2953d95b",
      "metadata": {
        "id": "2953d95b"
      },
      "outputs": [],
      "source": [
        "# install required dependencies\n",
        "! pip install \\\n",
        "    \"langchain\" \\\n",
        "    \"cassandra-driver>=3.28.0\" \\\n",
        "    \"cassio\" \\\n",
        "    \"google-cloud-aiplatform>=1.25.0\" \\\n",
        "    \"jupyter>=1.0.0\" \\\n",
        "    \"openai==0.27.7\" \\\n",
        "    \"tiktoken==0.4.0\" \\\n",
        "    \"pypdf\" \\\n",
        "    \"transformers\" \\\n",
        "    \"datasets\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222f44ff",
      "metadata": {
        "id": "222f44ff"
      },
      "source": [
        "You will likely be asked to \"Restart the Runtime\" at this time, as some dependencies\n",
        "have been upgraded. **Please do restart the runtime now** for a smoother execution from this point onward."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load a PDF file"
      ],
      "metadata": {
        "id": "VTebGKsNENFZ"
      },
      "id": "VTebGKsNENFZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your PDF document:\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print('Please upload a PDF to train')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    pdfFileTitle = list(uploaded.keys())[0]\n",
        "    PDF_PATH = os.path.join(os.getcwd(), pdfFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed loading a PDF file. Please re-run the cell.'\n",
        "    )"
      ],
      "metadata": {
        "id": "vfWxOITlDs9x",
        "outputId": "1759daf4-c6c3-46f7-9700-e4a945d82560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "id": "vfWxOITlDs9x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload a PDF to train\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e1242621-989a-46a3-983e-3f11593b8ecd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e1242621-989a-46a3-983e-3f11593b8ecd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003).pdf to McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(PDF_PATH)\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "Ls2QCj9GEa8U"
      },
      "id": "Ls2QCj9GEa8U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "id": "Pf30RVLSEhsP"
      },
      "id": "Pf30RVLSEhsP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the Astra DB Connection"
      ],
      "metadata": {
        "id": "eZS2Xsy0WY-c"
      },
      "id": "eZS2Xsy0WY-c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh4P-XUDq4u9",
        "outputId": "9ee42828-08f3-4094-895f-f29b433427f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Astra DB Keyspace name: vs_law\n"
          ]
        }
      ],
      "source": [
        "# Input your database keyspace name:\n",
        "ASTRA_DB_KEYSPACE = input('Your Astra DB Keyspace name: ')"
      ],
      "id": "zh4P-XUDq4u9"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUt_WX6_xwUP"
      },
      "id": "nUt_WX6_xwUP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lThGqYchq4u-",
        "outputId": "a728564f-205a-43d9-982e-0cd071026bcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Astra DB Token: AstraCS:clkwynJtAqjZKFCddWEbiakQ:9f3639a02e15023c840810faa41e69f3713a4bd22056bf5c7d87c03c5c831896\n"
          ]
        }
      ],
      "source": [
        "# Input your Astra DB token string, the one starting with \"AstraCS:...\"\n",
        "ASTRA_DB_TOKEN_BASED_PASSWORD = input('Your Astra DB Token: ')"
      ],
      "id": "lThGqYchq4u-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNQ6T_Gjk0Oz"
      },
      "source": [
        "### Astra DB Secure Connect Bundle\n",
        "\n",
        "Please upload the Secure Connect Bundle zipfile to connect to your Astra DB instance.\n",
        "\n",
        "The Secure Connect Bundle is needed to establish a secure connection to the database.\n",
        "Click [here](https://awesome-astra.github.io/docs/pages/astra/download-scb/#c-procedure) for instructions on how to download it from Astra DB."
      ],
      "id": "QNQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnNziXZ1q4vD",
        "outputId": "181dcab7-44a9-4208-c1f0-f74397abd1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your Secure Connect Bundle\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cea6ba26-0b6c-485a-857c-ebed11d68092\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cea6ba26-0b6c-485a-857c-ebed11d68092\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving secure-connect-law.zip to secure-connect-law.zip\n"
          ]
        }
      ],
      "source": [
        "# Upload your Secure Connect Bundle zipfile:\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print('Please upload your Secure Connect Bundle')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    astraBundleFileTitle = list(uploaded.keys())[0]\n",
        "    ASTRA_DB_SECURE_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
        "    )"
      ],
      "id": "xnNziXZ1q4vD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUDw-07Iq4vE"
      },
      "outputs": [],
      "source": [
        "# colab-specific override of helper functions\n",
        "from cassandra.cluster import (\n",
        "    Cluster,\n",
        ")\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "# The \"username\" is the literal string 'token' for this connection mode:\n",
        "ASTRA_DB_TOKEN_BASED_USERNAME = 'token'\n",
        "\n",
        "\n",
        "def getCQLSession(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        cluster = Cluster(\n",
        "            cloud={\n",
        "                \"secure_connect_bundle\": ASTRA_DB_SECURE_BUNDLE_PATH,\n",
        "            },\n",
        "            auth_provider=PlainTextAuthProvider(\n",
        "                ASTRA_DB_TOKEN_BASED_USERNAME,\n",
        "                ASTRA_DB_TOKEN_BASED_PASSWORD,\n",
        "            ),\n",
        "        )\n",
        "        astraSession = cluster.connect()\n",
        "        return astraSession\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')\n",
        "\n",
        "def getCQLKeyspace(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        return ASTRA_DB_KEYSPACE\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')"
      ],
      "id": "TUDw-07Iq4vE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCQ6T_Gjk0Oz"
      },
      "source": [
        "### LLM Provider\n",
        "\n",
        "In the cell below you can choose between **GCP VertexAI** or **OpenAI** for your LLM services.\n",
        "(See [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for more details).\n",
        "\n",
        "Make sure you set the `llmProvider` variable and supply the corresponding access secrets in the following cell."
      ],
      "id": "QXCQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGpzZc5zq4vG"
      },
      "outputs": [],
      "source": [
        "# Set your secret(s) for LLM access:\n",
        "llmProvider = 'OpenAI'  # 'GCP_VertexAI' # 'Hugging_Face'"
      ],
      "id": "pGpzZc5zq4vG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOFStlEAq4vH",
        "outputId": "ede99c07-f9e6-4a3e-f15f-a223be646bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your secret for LLM provider \"OpenAI\": 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\n"
          ]
        }
      ],
      "source": [
        "# Add in Hugging Face API portion\n",
        "if llmProvider == 'OpenAI':\n",
        "    apiSecret = input(f'Your secret for LLM provider \"{llmProvider}\": ')\n",
        "    os.environ['OPENAI_API_KEY'] = apiSecret\n",
        "elif llmProvider == 'GCP_VertexAI':\n",
        "    # we need a json file\n",
        "    print(f'Please upload your Service Account JSON for the LLM provider \"{llmProvider}\":')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        vertexAIJsonFileTitle = list(uploaded.keys())[0]\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.join(os.getcwd(), vertexAIJsonFileTitle)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'No file uploaded. Please re-run the cell.'\n",
        "        )\n",
        "else:\n",
        "    raise ValueError('Unknown/unsupported LLM Provider')"
      ],
      "id": "zOFStlEAq4vH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0rYQTmwq4vI"
      },
      "source": [
        "### Colab preamble completed\n",
        "\n",
        "The following cells constitute the demo notebook proper."
      ],
      "id": "W0rYQTmwq4vI"
    },
    {
      "cell_type": "markdown",
      "id": "6715bc2b",
      "metadata": {
        "id": "6715bc2b"
      },
      "source": [
        "# Vector Similarity Search QA Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761d9b70",
      "metadata": {
        "id": "761d9b70"
      },
      "source": [
        "_**NOTE:** this uses Cassandra's \"Vector Similarity Search\" capability.\n",
        "Make sure you are connecting to a vector-enabled database for this demo._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042f832e",
      "metadata": {
        "id": "042f832e"
      },
      "outputs": [],
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import (\n",
        "    CharacterTextSplitter,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4388ac1d",
      "metadata": {
        "id": "4388ac1d"
      },
      "source": [
        "The following line imports the Cassandra flavor of a LangChain vector store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65c46f0",
      "metadata": {
        "id": "d65c46f0"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4578a87b",
      "metadata": {
        "id": "4578a87b"
      },
      "source": [
        "A database connection is needed to access Cassandra. The following assumes\n",
        "that a _vector-search-capable Astra DB instance_ is available. Adjust as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11013224",
      "metadata": {
        "id": "11013224",
        "outputId": "1238a8da-e61a-4553-9d86-434268daa210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 3d123259-cbab-4680-96fe-063ce8fc2e8a-us-east1.db.astra.datastax.com:29042:ffdb2292-3485-48a0-b34b-11a62c0fff4f. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 3d123259-cbab-4680-96fe-063ce8fc2e8a-us-east1.db.astra.datastax.com:29042:ffdb2292-3485-48a0-b34b-11a62c0fff4f. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(133171267586896) 3d123259-cbab-4680-96fe-063ce8fc2e8a-us-east1.db.astra.datastax.com:29042:ffdb2292-3485-48a0-b34b-11a62c0fff4f> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 3d123259-cbab-4680-96fe-063ce8fc2e8a-us-east1.db.astra.datastax.com:29042:ffdb2292-3485-48a0-b34b-11a62c0fff4f. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "# creation of the DB connection\n",
        "cqlMode = 'astra_db'\n",
        "session = getCQLSession(mode=cqlMode)\n",
        "keyspace = getCQLKeyspace(mode=cqlMode)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e2a156",
      "metadata": {
        "id": "32e2a156"
      },
      "source": [
        "Both an LLM and an embedding function are required.\n",
        "\n",
        "Below is the logic to instantiate the LLM and embeddings of choice. We choose to leave it in the notebooks for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "124e3de4",
      "metadata": {
        "id": "124e3de4",
        "outputId": "07ee375c-2a9b-4d9f-b04f-e3990793a452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM+embeddings from OpenAI\n"
          ]
        }
      ],
      "source": [
        "# creation of the LLM resources\n",
        "\n",
        "if llmProvider == 'GCP_VertexAI':\n",
        "    from langchain.llms import VertexAI\n",
        "    from langchain.embeddings import VertexAIEmbeddings\n",
        "    llm = VertexAI()\n",
        "    myEmbedding = VertexAIEmbeddings()\n",
        "    print('LLM+embeddings from VertexAI')\n",
        "elif llmProvider == 'OpenAI':\n",
        "    from langchain.llms import OpenAI\n",
        "    from langchain.embeddings import OpenAIEmbeddings\n",
        "    llm = OpenAI(temperature=0)\n",
        "    myEmbedding = OpenAIEmbeddings()\n",
        "    print('LLM+embeddings from OpenAI')\n",
        "elif llmProvider == 'Hugging_Face'\n",
        "    from langchain.llms import HuggingFaceHub\n",
        "    from langchain.embeddings import HuggingFaceEmbeddings\n",
        "    # llm =\n",
        "    myEmbedding = HuggingFaceEmbeddings()\n",
        "\n",
        "else:\n",
        "    raise ValueError('Unknown LLM provider.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "285f29cf",
      "metadata": {
        "id": "285f29cf"
      },
      "source": [
        "## Langchain Retrieval Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf74a31",
      "metadata": {
        "id": "5cf74a31"
      },
      "source": [
        "The following is a minimal usage of the Cassandra vector store. The store is created and filled at once, and is then queried to retrieve relevant parts of the indexed text, which are then stuffed into a prompt finally used to answer a question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f29fc57",
      "metadata": {
        "id": "6f29fc57"
      },
      "source": [
        "The following creates an \"index creator\", which knows about the type of vector store, the embedding to use and how to preprocess the input text:\n",
        "\n",
        "_(Note: stores built with different embedding functions will need different tables. This is why we append the `llmProvider` name to the table name in the next cell.)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2cfe71b",
      "metadata": {
        "id": "d2cfe71b"
      },
      "outputs": [],
      "source": [
        "table_name = 'vs_law_pdf_' + llmProvider\n",
        "\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Cassandra,\n",
        "    embedding=myEmbedding,\n",
        "    text_splitter=CharacterTextSplitter(\n",
        "        chunk_size=400,\n",
        "        chunk_overlap=0,\n",
        "    ),\n",
        "    vectorstore_kwargs={\n",
        "        'session': session,\n",
        "        'keyspace': keyspace,\n",
        "        'table_name': table_name,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Cassandra Vector Store and clear entries if the table already exists"
      ],
      "metadata": {
        "id": "C7V7uPgvE3yY"
      },
      "id": "C7V7uPgvE3yY"
    },
    {
      "cell_type": "code",
      "source": [
        "myCassandraVStore = Cassandra(\n",
        "    embedding=myEmbedding,\n",
        "    session=session,\n",
        "    keyspace=keyspace,\n",
        "    table_name=table_name,\n",
        ")\n",
        "\n",
        "myCassandraVStore.clear()"
      ],
      "metadata": {
        "id": "SCxWxjRWl8Dg"
      },
      "id": "SCxWxjRWl8Dg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mySplitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=120)"
      ],
      "metadata": {
        "id": "6ITWD1pqmgeu"
      },
      "id": "6ITWD1pqmgeu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the function for creating a vector index for a Wikipedia entry"
      ],
      "metadata": {
        "id": "oogCCCXcv3yG"
      },
      "id": "oogCCCXcv3yG"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_index_for_page(page, myCassandraVStore):\n",
        "  page_chunks = mySplitter.transform_documents(page)\n",
        "  myCassandraVStore.add_documents(page_chunks)"
      ],
      "metadata": {
        "id": "mbsblXxQwAT9"
      },
      "id": "mbsblXxQwAT9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the create_vector_index function for each row in the Wikipedia dataframe. It's good time to grab a drink as the next step will take about 90 seconds to complete."
      ],
      "metadata": {
        "id": "ZCXx5rKUxj_z"
      },
      "id": "ZCXx5rKUxj_z"
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(PDF_PATH)\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "print(pages[0])"
      ],
      "metadata": {
        "id": "M3K5EOR1xrdO",
        "outputId": "febe75f2-e410-4eb8-a647-f95926b3ce85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "M3K5EOR1xrdO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='563\\n(1)\\nnas,\\ntortious\\ninterfer-\\non\\nboth\\ncounts\\nof\\ncom-\\nII\\nof\\nPlaintiffs\\non\\ncount\\njudgment\\n (2)\\nrelationship\\nand\\ndefa-\\nof\\neconomic\\npay\\nto\\nence\\nKenwood\\nover-\\nfailure\\nof\\nplaint\\nfor\\n counterclaim;\\nmation,\\nFurnas’s\\nstate\\nof\\nMaryland\\nunder\\ncompensation\\ntime\\n mo-\\ndeny\\nwill\\nDefendants’\\nThe\\ncourt\\nlaw.\\nthe\\naffi-\\nPlaintiffs\\nmotion\\nto\\nstrike\\n7.\\nPlain-\\nIII\\nand\\nYI\\nof\\ncounts\\ntion\\nto\\ndismiss\\nBE,\\nL.\\nand\\nthe\\nAshby\\ndavit\\nof\\nChamberlin\\n supervision\\ncomplaint\\nnegligent\\nfor\\ntiffs\\nIS,\\nDENIED;\\nand\\nhereby\\nsame\\nFurnas.\\nnegligence\\nby\\nKenwood\\nand\\nby\\ncopies\\ntransmit\\nof\\nthe\\n8.\\nThe\\nclerk\\nwill\\nmotion\\nto\\nDefendants’\\ngrant\\ncourt\\nwill\\nThe\\nthis\\nto\\nOpinion\\nMemorandum\\nand\\nOrder\\nPlaintiffs\\nand\\nVIII\\nof\\ncounts\\nVII\\ndismiss\\nparties.\\ncounsel\\nfor\\nthe\\nand\\nFur-\\nfailure\\nof\\nKenwood\\ncomplaint\\nfor\\n taxes\\nand\\nMedicare\\npay\\nto\\nretirement\\nnas\\n motion\\nfor\\nsum-\\nPlaintiffs\\nFICA.\\nunder\\n counterclaim\\non\\nFurnas’s\\nmary\\njudgment\\n motion\\nto\\nand\\nPlaintiffs\\ngranted\\nwill\\nbe\\n separate\\nA\\norder\\ndenied.\\nwill\\nbe\\nstrike\\nAN-\\nIn\\nre\\nMICROSOFT\\nCORP.\\nwill\\nfollow.\\nTITRUST\\nLITIGATION\\n ORDER\\nMcCall\\nforegoing\\nin\\nthe\\nthe\\nreasons\\nstated\\nFor\\nv.\\nthis-day\\nOpinion,\\nit\\nis\\nMemorandum\\n Corp.\\nMicrosoft\\n2003,\\nthe\\nStates\\nJanuary,\\nby\\nUnited\\nof\\n Mary-\\nof\\nfor\\nthe\\nDistrict\\nCourt\\nDistrict\\nMoscowitz\\nland,\\nthat:\\nORDERED\\nv.\\nsummary\\nmotion\\nfor\\n1.\\nDefendants’\\nCorp.\\nMicrosoft\\ncom-\\ncount\\nII\\nof\\nPlaintiffs\\njudgment\\non\\n BE,\\nand\\n56\\npursuant\\nto\\nFed.R.Civ.P.\\nplaint\\nHoward\\n IS,\\nDENIED;\\nhereby\\nthe\\nsame\\nv.\\n to\\ndismiss\\n2.\\nDefendants’\\nmotion\\nCorp.\\nMicrosoft\\nVI,\\ncomplaint\\nPlaintiffs\\nIII\\nand\\nof\\ncounts\\n 12(b)(6)\\nBE,\\nand\\nStrickley\\npursuant\\nto\\nFed.R.Civ.P.\\nDENIED;\\nIS,\\nhereby\\nthe\\nsame\\nv.\\n to\\ndismiss\\nDefendants’\\nmotion\\n3.\\nCorp.\\nMicrosoft\\n Plaintiffs\\ncom-\\nand\\nVIII\\nof\\ncounts\\nVII\\n Prentice\\n12(b)(6)\\npursuant\\nto\\nFed.R.Civ.P.\\nplaint\\n GRANTED;\\nIS,\\nBE,\\nhereby\\nsame\\nand\\nthe\\nv.\\n of\\nPlaintiffs\\nVII\\nand\\nVIII\\n4.\\nCounts\\nCorp.\\nMicrosoft\\n and\\nFur-\\nof\\nKenwood\\ncomplaint\\nfor\\nfailure\\nJFM-99-3897,\\n1332,\\nCIV.\\nMDL\\nNos.\\ntaxes\\nand\\nMedicare\\npay\\nto\\nretirement\\nnas\\nJFM-00-2446,\\nJFM-00-2444,\\nCIV.\\nCIV.\\nBE,\\nhereby\\nand\\nthe\\nsame\\nunder\\nFICA\\nJFM-00-2447,\\nJFM-00-2451.\\nCIV.\\nCIV.\\nDISMISSED;\\nARE,\\nCourt,\\nStates\\nDistrict\\nUnited\\nsummary\\njudg-\\nmotion\\nfor\\n5.\\nPlaintiffs\\nMaryland.\\nD.\\ncounterclaim\\nFurnas’s\\nment\\non\\nDefendant\\n 27,\\n2003.\\nJan.\\nGRANTED;\\nIS,\\nBE,\\nhereby\\nthe\\nsame\\nand\\n BE,\\nand\\nthe\\nsame\\n6.\\nJUDGMENT\\nIS,\\nGregory\\nin\\nfavor\\nof\\nENTERED\\nhereby\\nPaukstis,\\nChristopher\\nFur-\\nagainst\\nand\\nJ.' metadata={'source': '/content/McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003).pdf', 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pages))"
      ],
      "metadata": {
        "id": "EW7UFRvdFMYp",
        "outputId": "0d97d882-3f8c-4eb3-ba37-9aa30107ebc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EW7UFRvdFMYp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for page in pages:\n",
        "  page_chunks = mySplitter.transform_documents([page])\n",
        "  myCassandraVStore.add_documents(page_chunks)"
      ],
      "metadata": {
        "id": "bVE2Mf2rFEvp"
      },
      "id": "bVE2Mf2rFEvp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndexWrapper(vectorstore=myCassandraVStore)"
      ],
      "metadata": {
        "id": "fySPtKkYmAgh"
      },
      "id": "fySPtKkYmAgh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's query our proprietory store. We'll ask \"What is Andouille?\""
      ],
      "metadata": {
        "id": "geA-eXncFwvi"
      },
      "id": "geA-eXncFwvi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm really interested in what temperature to cook my andouille."
      ],
      "metadata": {
        "id": "tRiU4IMkF6di"
      },
      "id": "tRiU4IMkF6di"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the background of the McCall v. Microsoft Corp. case?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "S_96yaY45OFw",
        "outputId": "28a9a2a2-5db5-46bd-f1e2-04287872c41a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "S_96yaY45OFw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' McCall v. Microsoft Corp. was a case in the United States District Court for the District of Maryland in which the court held that Microsoft Corp. was liable for antitrust violations and common law enrichment.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who were the key parties involved in the case?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "XjNaRKGENLAz",
        "outputId": "cdd3822e-a745-49b1-ea30-41be95d84dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "XjNaRKGENLAz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The key parties involved in the case were Larry Derryberry, Solomon, Stephan G. Naifeh, Prentice, Microsoft Corp., Kenwood Corp., Furnas, and the state of Maryland.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who were the plaintiffs and who were the defendants?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "2JpmtYZMy2ur",
        "outputId": "f5508290-5d66-4879-c3fc-ac25df5e8bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The plaintiffs were Berman, Beerman, Steve W. Hagens, Christopher Lovell, P.S., Stewart, Richard C. Giovanniello, Earle Pepperman II, and Microsoft Corporation. The defendants were Kenwood Corporation, Furnas Corporation, and Tulchin, David B. Sullivan and Cromwell, PH/MDL, Charles B. Casper, Montgomery McCracken Walker and Rhoads Richard Wallis, Aeschbacher, and Steven J. Thomas Burt.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "id": "2JpmtYZMy2ur"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Can you give me a summary of this case?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "flsBieWL7KnP",
        "outputId": "3b6ba79e-79d4-446c-80bd-3f2def33cdff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "id": "flsBieWL7KnP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" This case involves Plaintiffs Gregory Paukstis and Christopher Furnas filing a motion for summary judgment in favor of them against Defendants Kenwood and J. YI on January 27, 2003. The court granted the motion and entered judgment in favor of the Plaintiffs. The court also denied the Defendants' counterclaim and motion to dismiss. The Plaintiffs were awarded compensation under the law of the state of Maryland for failure to pay overtime.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare this answer to what OpenAi GPT-3 will return"
      ],
      "metadata": {
        "id": "4uJebWz9JfAu"
      },
      "id": "4uJebWz9JfAu"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = apiSecret\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-003\",\n",
        "  prompt=\"What is the background of the McCall v. Microsoft Corp. case?\",\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "print(response.choices[0].text.strip())"
      ],
      "metadata": {
        "id": "zX48Pu3-Jl9B",
        "outputId": "10500e83-6b9c-4e56-9245-389b98fdba2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zX48Pu3-Jl9B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "McCall v. Microsoft Corp. was a lawsuit filed in 2004 by Frank E. McCall, Jr. alleging that Microsoft had violated anti-trust laws by requiring the purchase of its proprietary operating system in order to use Microsoft Office software. McCall, a law student from North Carolina, claimed that the practice precluded him from purchasing a cheaper alternative, such as Linux-based office suites, thereby giving Microsoft an unfair market advantage. Microsoft denied the allegation, claiming that its products were simply\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You've now seen how we can use a LLM to answer the prompt from our Astra Vector Store, but notice that the answer is different from using the LLM directly."
      ],
      "metadata": {
        "id": "GmIdlZngKvtU"
      },
      "id": "GmIdlZngKvtU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get some information about the source for the response to the question \"What temperature should Andouille be cooked?\""
      ],
      "metadata": {
        "id": "DikzwEj0Gawb"
      },
      "id": "DikzwEj0Gawb"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.vectorstore.as_retriever(search_kwargs={\n",
        "    'k': 2,\n",
        "})"
      ],
      "metadata": {
        "id": "a5MrZWD7uaBa"
      },
      "id": "a5MrZWD7uaBa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\n",
        "    \"What temperature should Andouille be cooked?\"\n",
        ")"
      ],
      "metadata": {
        "id": "dg1FUbYoudSr"
      },
      "id": "dg1FUbYoudSr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}